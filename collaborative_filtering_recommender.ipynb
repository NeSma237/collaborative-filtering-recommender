{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsDLhFXmB5GGioHPOI8fIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeSma237/collaborative-filtering-recommender/blob/main/collaborative_filtering_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir collaborative-filtering-recommender\n",
        "!cd collaborative-filtering-recommender\n",
        "!mkdir data notebooks src results\n",
        "!touch README.md requirements.txt\n",
        "!touch README.md requirements.txt"
      ],
      "metadata": {
        "id": "N4v1pPnB_wKh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "movies = pd.read_csv('ml-100k/u.item', sep='|', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'], encoding='latin-1')\n",
        "users = pd.read_csv('ml-100k/u.user', sep='|', names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UxTJgTf_7h9",
        "outputId": "c0dfaa18-8376-4188-b17a-64a629fc095f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-25 17:44:53--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  5.53MB/s    in 0.8s    \n",
            "\n",
            "2025-04-25 17:44:54 (5.53 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class UserBasedCF:\n",
        "    def __init__(self):\n",
        "        self.user_similarity = None\n",
        "        self.ratings_matrix = None\n",
        "\n",
        "    def fit(self, ratings_df):\n",
        "        # Create user-item matrix\n",
        "        self.ratings_matrix = ratings_df.pivot_table(\n",
        "            index='user_id',\n",
        "            columns='movie_id',\n",
        "            values='rating'\n",
        "        ).fillna(0)\n",
        "\n",
        "        # Compute user similarity\n",
        "        self.user_similarity = cosine_similarity(self.ratings_matrix)\n",
        "\n",
        "    def predict(self, user_id, movie_id, k=5):\n",
        "        if user_id not in self.ratings_matrix.index or movie_id not in self.ratings_matrix.columns:\n",
        "            return 0  # or handle missing data\n",
        "\n",
        "        # Get similar users\n",
        "        user_idx = self.ratings_matrix.index.get_loc(user_id)\n",
        "        similar_users = np.argsort(-self.user_similarity[user_idx])[1:k+1]  # exclude self\n",
        "\n",
        "        # Calculate weighted average of ratings from similar users\n",
        "        weighted_sum = 0\n",
        "        similarity_sum = 0\n",
        "\n",
        "        for sim_user_idx in similar_users:\n",
        "            sim_user_id = self.ratings_matrix.index[sim_user_idx]\n",
        "            rating = self.ratings_matrix.loc[sim_user_id, movie_id]\n",
        "            if rating > 0:\n",
        "                similarity = self.user_similarity[user_idx, sim_user_idx]\n",
        "                weighted_sum += similarity * rating\n",
        "                similarity_sum += similarity\n",
        "\n",
        "        if similarity_sum == 0:\n",
        "            return 0\n",
        "\n",
        "        return weighted_sum / similarity_sum"
      ],
      "metadata": {
        "id": "CELLelimFHYH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
        "\n",
        "    # First map the predictions to each user\n",
        "    user_est_true = {}\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        if uid not in user_est_true:\n",
        "            user_est_true[uid] = []\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                             for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        precisions.append(n_rel_and_rec_k / k if k != 0 else 0)\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        recalls.append(n_rel_and_rec_k / n_rel if n_rel != 0 else 0)\n",
        "\n",
        "    return np.mean(precisions), np.mean(recalls)"
      ],
      "metadata": {
        "id": "mNBPCCGSFZGt"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}