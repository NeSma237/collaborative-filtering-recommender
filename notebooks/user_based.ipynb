{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrLIQA9ZGgNBO1Q6w8iOfQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeSma237/collaborative-filtering-recommender/blob/main/notebooks/user_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir collaborative-filtering-recommender\n",
        "!cd collaborative-filtering-recommender\n",
        "!mkdir data notebooks src results\n",
        "!touch README.md requirements.txt\n",
        "!touch README.md requirements.txt"
      ],
      "metadata": {
        "id": "N4v1pPnB_wKh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "movies = pd.read_csv('ml-100k/u.item', sep='|', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'], encoding='latin-1')\n",
        "users = pd.read_csv('ml-100k/u.user', sep='|', names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1UxTJgTf_7h9",
        "outputId": "c0dfaa18-8376-4188-b17a-64a629fc095f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-25 17:44:53--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  5.53MB/s    in 0.8s    \n",
            "\n",
            "2025-04-25 17:44:54 (5.53 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import Dataset, Reader\n",
        "!pip install numpy==1.23.5 --force-reinstall\n",
        "!pip install scikit-surprise\n"
      ],
      "metadata": {
        "id": "ex_SCyVcUuDl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_item_matrix = pd.read_csv(\"data/merged_data.csv\", index_col='user_id')\n",
        "print(\"User-Item Matrix Shape:\", user_item_matrix.shape)\n",
        "print(\"Sample (First 5 Users, First 5 Movies):\")\n",
        "print(user_item_matrix.iloc[:5, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbgOORobUx9t",
        "outputId": "43c7f3f8-0ccc-4e73-d151-0fc101868ae7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Item Matrix Shape: (100000, 30)\n",
            "Sample (First 5 Users, First 5 Movies):\n",
            "         item_id  rating  timestamp                       title release_date\n",
            "user_id                                                                     \n",
            "196          242       3  881250949                Kolya (1996)  24-Jan-1997\n",
            "186          302       3  891717742    L.A. Confidential (1997)  01-Jan-1997\n",
            "22           377       1  878887116         Heavyweights (1994)  01-Jan-1994\n",
            "244           51       2  880606923  Legends of the Fall (1994)  01-Jan-1994\n",
            "166          346       1  886397596         Jackie Brown (1997)  01-Jan-1997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original ratings data (not the user-item matrix)\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp']) # Changed the file path to 'ml-100k/u.data'\n",
        "\n",
        "# Define the rating scale (1-5)\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load data into Surprise format\n",
        "data = Dataset.load_from_df(ratings[['user_id', 'item_id', 'rating']], reader)\n",
        "\n",
        "# Split into train-test (80-20)\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "# Correct way to check sizes:\n",
        "\n",
        "print(f\"Train set size: {trainset.n_ratings} ratings\")\n",
        "print(f\"Test set size: {len(testset)} ratings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF9IYHRHVaz5",
        "outputId": "129867b8-1141-4118-b931-3d1ad5dc05e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 80000 ratings\n",
            "Test set size: 20000 ratings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import Dataset, Reader\n",
        "#!pip install numpy==1.23.5 --force-reinstall\n",
        "#!pip install scikit-surprise\n",
        "# Calculate cosine similarity between users\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "movies = pd.read_csv('ml-100k/u.item', sep='|', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'], encoding='latin-1')\n",
        "\n",
        "# Merge ratings and movies data on 'movie_id'\n",
        "data = pd.merge(ratings, movies, left_on='movie_id', right_on='movie_id') # Specifying left_on and right_on\n",
        "\n",
        "# Create user-item matrix\n",
        "user_item_matrix = data.pivot_table(\n",
        "    index='user_id',\n",
        "    columns='movie_title',  # Changed to 'movie_title' assuming it's the movie identifier\n",
        "    values='rating',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "# Now you can calculate the cosine similarity\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "user_similarity = pd.DataFrame(\n",
        "    user_similarity,\n",
        "    index=user_item_matrix.index,\n",
        "    columns=user_item_matrix.index\n",
        ")\n",
        "\n",
        "print(\"User Similarity Matrix Shape:\", user_similarity.shape)\n",
        "print(\"Sample (First 5 Users):\")\n",
        "print(user_similarity.iloc[:5, :5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxfdq6Y9V0Te",
        "outputId": "8ef86fcf-098a-4401-ab10-0a58fdd1de59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Similarity Matrix Shape: (943, 943)\n",
            "Sample (First 5 Users):\n",
            "user_id         1         2         3         4         5\n",
            "user_id                                                  \n",
            "1        1.000000  0.168937  0.048388  0.064561  0.379670\n",
            "2        0.168937  1.000000  0.113393  0.179694  0.073623\n",
            "3        0.048388  0.113393  1.000000  0.349781  0.021592\n",
            "4        0.064561  0.179694  0.349781  1.000000  0.031804\n",
            "5        0.379670  0.073623  0.021592  0.031804  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating(user_id, movie_title, k=5):\n",
        "\n",
        "    # Get similarity scores for the target user\n",
        "    sim_scores = user_similarity.loc[user_id]\n",
        "\n",
        "    # Get ratings for the target movie\n",
        "    movie_ratings = user_item_matrix[movie_title]\n",
        "\n",
        "    # Remove users who haven't rated the movie\n",
        "    valid_users = movie_ratings[movie_ratings > 0].index\n",
        "    sim_scores = sim_scores[valid_users]\n",
        "\n",
        "    # Get top-K most similar users\n",
        "    top_k_users = sim_scores.sort_values(ascending=False)[1:k+1]  # Exclude self\n",
        "\n",
        "    # Calculate weighted average\n",
        "    weighted_sum = np.dot(\n",
        "        top_k_users.values,\n",
        "        user_item_matrix.loc[top_k_users.index, movie_title]\n",
        "    )\n",
        "    prediction = weighted_sum / top_k_users.sum()\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "tED_99IqV4cF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 1\n",
        "movie_title = \"Toy Story (1995)\"\n",
        "predicted_rating = predict_rating(user_id, movie_title, k=5)\n",
        "\n",
        "print(f\"Predicted rating for User {user_id} on '{movie_title}': {predicted_rating:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7u8X07iV9hY",
        "outputId": "68a0ae80-5498-440f-a5a9-f5ef5f6b27e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for User 1 on 'Toy Story (1995)': 4.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_id, n=5):\n",
        "    \"\"\"\n",
        "    Recommends top-N movies a user hasn't rated yet.\n",
        "    \"\"\"\n",
        "    # Movies the user has already rated\n",
        "    rated_movies = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
        "\n",
        "    # Predict ratings for unrated movies\n",
        "    predictions = []\n",
        "    for movie in user_item_matrix.columns:\n",
        "        if movie not in rated_movies:\n",
        "            pred = predict_rating(user_id, movie)\n",
        "            predictions.append((movie, pred))\n",
        "\n",
        "    # Sort by predicted rating\n",
        "    recommendations = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Example: Get top 5 recommendations for User 1\n",
        "user_id = 1\n",
        "recommendations = recommend_movies(user_id, n=5)\n",
        "\n",
        "print(f\"Top 5 Recommendations for User {user_id}:\")\n",
        "for i, (movie, rating) in enumerate(recommendations, 1):\n",
        "    print(f\"{i}. {movie} (Predicted Rating: {rating:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEzo4CZHWEuu",
        "outputId": "f6aa869a-5e07-40df-8b01-7921a3e4000a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-aa40b963a197>:21: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  prediction = weighted_sum / top_k_users.sum()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Recommendations for User 1:\n",
            "1. Kundun (1997) (Predicted Rating: 4.59)\n",
            "2. 8 Seconds (1994) (Predicted Rating: 4.50)\n",
            "3. 8 1/2 (1963) (Predicted Rating: 4.39)\n",
            "4. Boogie Nights (1997) (Predicted Rating: 4.21)\n",
            "5. African Queen, The (1951) (Predicted Rating: 4.01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_predict(testset, user_similarity, user_item_matrix, movies, k=5):\n",
        "\n",
        "    # Create mapping dictionaries for faster lookups\n",
        "    movie_id_to_title = dict(zip(movies['item_id'], movies['title']))\n",
        "    user_mean_ratings = user_item_matrix.mean(axis=1)\n",
        "    global_mean = user_item_matrix.mean().mean()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    # Pre-compute all possible movie titles in test set\n",
        "    test_movies = {movie for _, movie, _ in testset}\n",
        "    available_movies = set(movie_id_to_title.keys())\n",
        "\n",
        "    for user, movie, _ in testset:\n",
        "        # Skip if movie not in our training data\n",
        "        if movie not in available_movies:\n",
        "            predictions.append(global_mean)\n",
        "            continue\n",
        "\n",
        "        movie_title = movie_id_to_title[movie]\n",
        "\n",
        "        try:\n",
        "            # Get similar users (excluding self)\n",
        "            sim_scores = user_similarity.loc[user]\n",
        "            user_ratings = user_item_matrix[movie_title]\n",
        "\n",
        "            # Find users who rated this movie\n",
        "            rated_users = user_ratings[user_ratings > 0].index\n",
        "            rated_users = rated_users[rated_users != user]  # Exclude self\n",
        "\n",
        "            if len(rated_users) == 0:\n",
        "                predictions.append(user_mean_ratings.loc[user])\n",
        "                continue\n",
        "\n",
        "            # Get top K similar users who rated this movie\n",
        "            user_sims = sim_scores[rated_users]\n",
        "            top_k_users = user_sims.nlargest(k).index\n",
        "\n",
        "            # Calculate weighted average\n",
        "            weighted_sum = (user_item_matrix.loc[top_k_users, movie_title] *\n",
        "                          user_similarity.loc[user, top_k_users]).sum()\n",
        "            norm = user_similarity.loc[user, top_k_users].sum()\n",
        "\n",
        "            prediction = weighted_sum / norm if norm != 0 else user_mean_ratings.loc[user]\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        except:\n",
        "            predictions.append(global_mean)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "RR9oWgyGWUou"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_at_k(user_id, ratings_df, movies_df, k=5, threshold=3.5):\n",
        "\n",
        "    # Get ground truth (movies the user rated highly)\n",
        "    user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
        "    # Changed 'item_id' to 'movie_id' to match the column name in ratings_df\n",
        "    highly_rated = set(user_ratings[user_ratings['rating'] >= threshold]['movie_id'])\n",
        "\n",
        "    # Get recommendations (assuming recommend_movies exists)\n",
        "    recommended_movies = recommend_movies(user_id, n=k)\n",
        "\n",
        "    # Convert recommendations to item IDs\n",
        "    recommended = []\n",
        "    for movie_title, _ in recommended_movies:\n",
        "        # Assuming 'movie_id' is the correct column in movies_df\n",
        "        movie_id = movies_df[movies_df['movie_title'] == movie_title]['movie_id'].values\n",
        "        if len(movie_id) > 0:\n",
        "            recommended.append(movie_id[0])\n",
        "\n",
        "    # Calculate metrics\n",
        "    relevant_and_recommended = len(highly_rated.intersection(recommended))\n",
        "    precision = relevant_and_recommended / k\n",
        "    recall = relevant_and_recommended / len(highly_rated) if highly_rated else 0\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "movies = pd.read_csv('ml-100k/u.item', sep='|', names=['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'], encoding='latin-1')\n",
        "\n",
        "\n",
        "# Then evaluate for a user\n",
        "precision, recall = precision_recall_at_k(\n",
        "    user_id=1,\n",
        "    ratings_df=ratings,\n",
        "    movies_df=movies,\n",
        "    k=5\n",
        ")\n",
        "print(f\"Precision@5: {precision:.2f}, Recall@5: {recall:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcT12crdWa8y",
        "outputId": "60ddee28-6aa3-4fc5-e561-4bf0a8168f49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-aa40b963a197>:21: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  prediction = weighted_sum / top_k_users.sum()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@5: 0.00, Recall@5: 0.00\n"
          ]
        }
      ]
    }
  ]
}